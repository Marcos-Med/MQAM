{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística\n",
    "<p>Aplicação da técnica de regressão logística para analisar a popularidade dos filmes entre 2000 a 2024</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as ny\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDateFrame(fileCSV):\n",
    "    dataFrame = pd.read_csv(fileCSV)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformY(data):\n",
    "   data[\"popularidade\"] = (data[\"popularidade\"] > data[\"popularidade\"].mean()).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateXY(data, columns):\n",
    "    y = data[\"popularidade\"]\n",
    "    x = data[columns]\n",
    "    return train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(x_train, y_train):\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createDateFrame(\"../T2/Transform.csv\")\n",
    "transformY(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_metrics(y_test, x_test, pred, model):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    conf_matrix = confusion_matrix(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(x_test)[:, 1])\n",
    "    print(f\"Acurácia: {accuracy:.2f}\")\n",
    "    print(f\"Precisão: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "    print(f\"AUC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(columns):\n",
    "    X_train, X_test, Y_train, Y_test = dateXY(df, columns)\n",
    "    model = createModel(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    result_metrics(Y_test, X_test, Y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.58\n",
      "Precisão: 0.65\n",
      "Recall: 0.55\n",
      "F1 Score: 0.60\n",
      "Matriz de Confusão:\n",
      " [[48 31]\n",
      " [46 57]]\n",
      "AUC: 0.61\n"
     ]
    }
   ],
   "source": [
    "logit(['orcamento', 'receita', 'duracao', 'voto_popular', 'avaliacao_da_critica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.57\n",
      "Precisão: 0.63\n",
      "Recall: 0.55\n",
      "F1 Score: 0.59\n",
      "Matriz de Confusão:\n",
      " [[46 33]\n",
      " [46 57]]\n",
      "AUC: 0.61\n"
     ]
    }
   ],
   "source": [
    "logit(['orcamento', 'receita', 'duracao', 'voto_popular'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.58\n",
      "Precisão: 0.65\n",
      "Recall: 0.54\n",
      "F1 Score: 0.59\n",
      "Matriz de Confusão:\n",
      " [[49 30]\n",
      " [47 56]]\n",
      "AUC: 0.58\n"
     ]
    }
   ],
   "source": [
    "logit(['orcamento', 'receita', 'duracao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.58\n",
      "Precisão: 0.65\n",
      "Recall: 0.54\n",
      "F1 Score: 0.59\n",
      "Matriz de Confusão:\n",
      " [[49 30]\n",
      " [47 56]]\n",
      "AUC: 0.57\n"
     ]
    }
   ],
   "source": [
    "logit(['orcamento', 'receita'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.58\n",
      "Precisão: 0.65\n",
      "Recall: 0.54\n",
      "F1 Score: 0.59\n",
      "Matriz de Confusão:\n",
      " [[49 30]\n",
      " [47 56]]\n",
      "AUC: 0.56\n"
     ]
    }
   ],
   "source": [
    "logit(['orcamento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo dados adicionais para a realização da análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenTMDB = \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIzZjZiNzNmOGE3NmNjZjA0OWU5OTQ2MzRhNWEyYjI3MyIsIm5iZiI6MTcyNDM4MzY5OC4wNzE4NjEsInN1YiI6IjY2YzYxN2YzNTk2MWNlZTg3ZTY5ZWQzYSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.ogQ7duMdbP16GPUyGSB5E200SjzropEXsuZUvgxxVzs\"\n",
    "def getProvidersMovie(token, ID):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {}\".format(token)\n",
    "        }\n",
    "        url = \"https://api.themoviedb.org/3/movie/{}/watch/providers\".format(ID)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"Error fetching data 1\")\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    except KeyError:\n",
    "        print(\"keyError 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, movie in df.iterrows():\n",
    "    data = getProvidersMovie(tokenTMDB, movie['id'])\n",
    "    i = 0\n",
    "    providers = []\n",
    "    for country in data['results']:\n",
    "        if 'flatrate' in data['results'][country]:\n",
    "            for plataform in data['results'][country]['flatrate']:\n",
    "                if(not(plataform['provider_name'] in providers)):\n",
    "                    i+=1\n",
    "                    providers.append(plataform['provider_name'])\n",
    "    df.at[index, 'total_streaming'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReleaseDate(token, ID):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {}\".format(token)\n",
    "        }\n",
    "        url = \"https://api.themoviedb.org/3/movie/{}/release_dates\".format(ID)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"Error fetching data 1\")\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    except KeyError:\n",
    "        print(\"keyError 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, movie in df.iterrows():\n",
    "    data = getReleaseDate(tokenTMDB, movie['id'])\n",
    "    i = len(data['results'])\n",
    "    df.at[index, 'total_countries'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetailsMovie(token, ID):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {}\".format(token)\n",
    "        }\n",
    "        url = \"https://api.themoviedb.org/3/movie/{}?language=pt-BR\".format(ID)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"Error fetching data 1\")\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    except KeyError:\n",
    "        print(\"keyError 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_detalhes_premios(awards_string):\n",
    "    if not awards_string:\n",
    "        return {\n",
    "            'total_wins': 0,\n",
    "            'total_nominations': 0,\n",
    "            'oscar_wins': False\n",
    "        }\n",
    "\n",
    "    # Captura o número de prêmios ganhos (combina \"X wins\", \"X win\" ou \"Won X awards\")\n",
    "    wins = re.findall(r'(\\d+) wins?|Won (\\d+)', awards_string)\n",
    "    total_wins = sum(int(won or win) for win, won in wins if win or won)\n",
    "\n",
    "    # Captura o número de indicações\n",
    "    nominations = re.search(r'(\\d+) nominations?', awards_string)\n",
    "    total_nominations = int(nominations.group(1)) if nominations else 0\n",
    "\n",
    "    # Captura o número de Oscars ganhos\n",
    "    oscar = re.search(r'Won (\\d+) Oscar', awards_string)\n",
    "    oscar_wins = int(oscar.group(1)) if oscar else 0\n",
    "\n",
    "    return {\n",
    "        'total_wins': total_wins,\n",
    "        'total_nominations': total_nominations,\n",
    "        'oscar_wins': oscar_wins > 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieOMDB(keyAPI, ID):\n",
    "    try:\n",
    "        url = \"http://www.omdbapi.com/?i={}&plot=full&apikey={}\".format(ID,keyAPI)\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"Error fetching data 2\")\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"Errod decoding JSON\")\n",
    "    except KeyError:\n",
    "        print(\"keyError 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenOMDB = \"d29535f4\"\n",
    "\n",
    "def process_movie(movie):\n",
    "    data = getDetailsMovie(tokenTMDB, movie['id'])\n",
    "    imdb_id = data['imdb_id'] \n",
    "    awards_data = getMovieOMDB(tokenOMDB, imdb_id)\n",
    "    return extrair_detalhes_premios(awards_data['Awards'])\n",
    "\n",
    "# Armazena os resultados em um dicionário para associar o índice ao resultado\n",
    "results = {}\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(process_movie, movie): index for index, (_, movie) in enumerate(df.iterrows())}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        index = futures[future]  # Obtém o índice correspondente\n",
    "        try:\n",
    "            awards_data = future.result()\n",
    "            results[index] = awards_data  # Armazena o resultado no dicionário\n",
    "        except Exception as exc:\n",
    "            print(f\"Index {index} generated an exception: {exc}\")\n",
    "\n",
    "# Atualiza o DataFrame com os resultados armazenados\n",
    "for index, awards_data in results.items():\n",
    "    df.at[index, 'total_awards'] = awards_data.get('total_wins', 0)\n",
    "    df.at[index, 'total_nominations'] = awards_data.get('total_nominations', 0)\n",
    "    df.at[index, 'oscar_wins'] = awards_data.get('oscar_wins', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLanguages(token, ID):\n",
    "  try:\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {}\".format(token)\n",
    "        }\n",
    "        url = \"https://api.themoviedb.org/3/movie/{}/translations\".format(ID)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        return data\n",
    "  except requests.exceptions.RequestException:\n",
    "        print(\"Error fetching data 1\")\n",
    "  except json.decoder.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "  except KeyError:\n",
    "        print(\"keyError 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, movie in df.iterrows():\n",
    "    data = getLanguages(tokenTMDB, movie['id'])\n",
    "    i = len(data['translations'])\n",
    "    df.at[index, 'total_languages'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(data, filename):\n",
    "    dataFrame = pd.DataFrame(data)\n",
    "    dataFrame.to_csv(filename, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCSV(df, \"Dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
